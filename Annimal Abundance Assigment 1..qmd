---
title: "Analysis_AA"
format: html
editor: visual
---

```{r}
library(Distance)
remotes::install_github("https://github.com/chrissuthy/statsecol")
library(statsecol)
library(tidyverse)
data('bowhead_LT')
library(ggplot2)
```

# **Exploratory Data Analysis**

```{r}
# Extend the range of breaks slightly beyond the maximum value to ensure that we see all of the values
# Use the smallest bin Width possible so that we can see the data as clearly as possible
max_distance <- max(bowhead_LT$distance, na.rm = TRUE)
breaks_seq <- seq(0, max_distance + 0.1, by = 0.08)

hist(bowhead_LT$distance, breaks = breaks_seq, 
     xlab = "Distance (Km)", 
     main = "Histogram of Whale Sighting Distances", 
     col = adjustcolor("steelblue", 0.1), 
     las = 1)


# Save the plot as a PNG file named "rawhistogram.png"
png(filename = "png/rawhistogram.png", width = 1300, height = 900, units = "px", res = 300)
hist(bowhead_LT$distance, breaks = breaks_seq, 
     xlab = "Distance (Km)", 
     main = "Histogram of Whale Sighting Distances", 
     col = adjustcolor("steelblue", 0.1), 
     las = 1)
dev.off()

```

```{r}
# Create a binned histogram with the probability of sightings
max_distance <- max(bowhead_LT$distance, na.rm = TRUE)
breaks_seq <- seq(0, max_distance + 0.1, by = 0.2)

# Calculate the histogram
hist_data <- hist(bowhead_LT$distance, breaks = breaks_seq, plot = FALSE)

# Calculate the proportions
proportions <- hist_data$counts / sum(hist_data$counts)

# Create the bar plot
barplot(proportions, names.arg = hist_data$mids, 
        xlab = "Distance (Km)", 
        ylab = "Proportion", 
        main = "Histogram of Whale Sighting Distances", 
        col = adjustcolor("steelblue", 0.1), 
        las = 1)

# Save the plot as a PNG file named "binned_histogram.png"
png(filename = "png/binned_histogram.png", width = 1300, height = 900, units = "px", res = 300)
barplot(proportions, names.arg = hist_data$mids, 
        xlab = "Distance (Km)", 
        ylab = "Proportion", 
        main = "Histogram of Whale Sighting Distances", 
        col = adjustcolor("steelblue", 0.1), 
        las = 1)
dev.off()


```

**Possible Covariates:**

```{r}
# Aggregate data to get the number of sightings per group size
sightings_per_size <- aggregate(bowhead_LT$distance, 
                                by = list(bowhead_LT$size), 
                                FUN = length)

# Rename columns for clarity
colnames(sightings_per_size) <- c("Group_Size", "Number_of_Sightings")

# Fit a linear model
model <- lm(Number_of_Sightings ~ Group_Size, data = sightings_per_size)

# Create the scatter plot with 'number of sightings' on the x-axis and 'group size' on the y-axis
plot(sightings_per_size$Group_Size, sightings_per_size$Number_of_Sightings, 
     main = "Number of Sightings per Group Size", 
     xlab = "Group Size", 
     ylab = "Number of Sightings", 
     pch = 19, col = "lightblue")

# Add a regression line
abline(model, col = "steelblue")

# Save the plot as a PNG file named "scatter_plot_regression.png" in the "png" folder
png(filename = "png/scatter_plot_number_of_sightings_per_group_size.png", width = 1300, height = 900, units = "px", res = 300)
plot(sightings_per_size$Group_Size, sightings_per_size$Number_of_Sightings, 
     main = "Number of Sightings per Group Size", 
     xlab = "Group Size", 
     ylab = "Number of Sightings", 
     pch = 19, col = "lightblue")
abline(model, col = "steelblue")
dev.off()
```

```{r}
# Count occurrences of each region label
region_counts <- table(bowhead_LT$Region.Label)

# Convert the counts to a data frame
region_counts_df <- as.data.frame(region_counts)
names(region_counts_df) <- c("Region.Label", "Number_of_Sightings")

# Plotting with ggplot2
library(ggplot2)

# Create the bar plot
ggplot(region_counts_df, aes(x = Region.Label, y = Number_of_Sightings)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  labs(x = "Stratum", 
       y = "Number of Sightings", 
       title = "Number of Sightings per Stratum") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Save the plot as a PNG file named "bar_plot_sightings_per_stratum.png"
ggsave(filename = "png/bar_plot_sightings_per_stratum.png", plot = last_plot(), width = 10, height = 6)

```

the main takeaways from the exploratory analysis are the following:

-   There is a clear imbalance, the mentions issues with the data and there could be mention of this but this point has to be explored as it really is the main issue here

-   Secondly the hist shows that we need to truncate further as there is some heterogeneity in the distances sampled

# **Fitting**

### I) fitting Key functions alone

```{r}
conversion <- convert_units("kilometre", "kilometre","square kilometre")
region <- unique(bowhead_LT[,c("Region.Label", "Area")])
sample <- unique(bowhead_LT[,c("Region.Label", "Sample.Label", "Effort")])
observation <- unique(bowhead_LT[,c("object", "Region.Label", "Sample.Label")])
```

```{r}
print('model with Half normal Key function, alone')
hn.noadj.trunc0 <- ds(data = bowhead_LT, key = "hn", adjustment = NULL, convert_units = conversion)

print('model with Hazard rate Key function, alone')
hr.noadj.trunc0 <- ds(data = bowhead_LT, key = "hr", adjustment = NULL, convert_units = conversion)

print('model with Uniform Key function, with no adjustment')
unif.noadj.trunc0 <- ds(data = bowhead_LT, key = "unif", adjustment = NULL, convert_units = conversion)

# We fit the Uniform with the cosine adj because the book did it and look at that better preformance (interesting)
print('model with Uniform Key function, with cosine adjustment')
unif.cos.trunc0 <- ds(data = bowhead_LT, key = "unif", adjustment = 'cos', convert_units = conversion)
```

```{r}
par(mfrow = c(1,2))

plot(hn.noadj.trunc0, which=2, pl.col = adjustcolor("lightblue",0.5),border=NULL, lwd = 2, ylab = "Detection probability (g(x))", xlab = "Distance", las=1, main = "Half-normal model Alone")

plot(hr.noadj.trunc0, which=2, pl.col = adjustcolor("lightblue",0.5),border=NULL, lwd = 2, ylab = "Detection probability (g(x))", xlab = "Distance", las=1, main = "Hazard rate model ALone")
```

```{r}
par(mfrow = c(1,2))
plot(unif.noadj.trunc0, which=2, pl.col = adjustcolor("lightblue",0.5),border=NULL, lwd = 2, ylab = "Detection probability (g(x))", xlab = "Distance", las=1, main = "Uniform model ALone")

plot(unif.cos.trunc0, which=2, pl.col = adjustcolor("lightblue",0.5),border=NULL, lwd = 2, ylab = "Detection probability (g(x))", xlab = "Distance", las=1, main = "Uniform, cos adjustment")
```

**Image download**

```{r}
# Save the plots as PNG files
png("png/plots-hr0adj-hn0adj.png", width = 800, height = 400) # Adjust width and height as needed
par(mfrow = c(1, 2))
plot(hn.noadj.trunc0, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Half-normal model")
plot(hr.noadj.trunc0, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Hazard rate model")
dev.off()

# Save the plots as PNG files
png("png/plots-unifcos-unif0adj.png", width = 800, height = 400) # Adjust width and height as needed
par(mfrow = c(1, 2))
plot(unif.cos.trunc0, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Uniform, cos adjustment")
plot(unif.noadj.trunc0, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Uniform")
dev.off()

```

### II) fitting Half Normal and Hazard rate with adjustments

A forwards stepping method is used

```{r}
# Half Normal
print('model with Half normal Key function, and Cosine adjustment')
hn.cos.trunc0<- ds(data = bowhead_LT, key = "hn", adjustment = "cos", convert_units = conversion)

print('model with Half normal Key function, and Hermite polynomial adjustment')
hn.herm.trunc0<- ds(data = bowhead_LT, key = "hn", adjustment = "herm", convert_units = conversion)

print('model with Half normal Key function, and polynomial adjustment')
hn.poly.trunc0<- ds(data = bowhead_LT, key = "hn", adjustment = "poly", convert_units = conversion)

# Hazard Rate
print('model with Hazard rate Key function, and Cosine adjustment')
hr.cos.trunc0<- ds(data = bowhead_LT, key = "hr", adjustment = "cos", convert_units = conversion)

print('model with Hazard rate Key function, and Hermite polynomial adjustment')
hr.herm.trunc0<- ds(data = bowhead_LT, key = "hr", adjustment = "herm", convert_units = conversion)

print('model with Hazard rate Key function, and polynomial adjustment')
hr.poly.trunc0<- ds(data = bowhead_LT, key = "hr", adjustment = "poly", convert_units = conversion)
```

We can see that the adjustment terms offer no improvement over the base Half normal and Harzard rate functions. and that the plots for hazard rate alone and Halph normal by itself have the following desirable prperties.

-   Shoulder

-   Non-increasing.

Burnham and Anderson (2002) suggested that models with a Î”AIC value of around two or less should be deemed to be well supported by the data

```{r}
par(mfrow = c(1,2))
# Plot for Half-Normal model with Cosine adjustment
plot(hn.cos.trunc0, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Half-Normal model with Cosine Adjustment")

# Plot for Half-Normal model with Hermite polynomial adjustment
plot(hn.herm.trunc0, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Half-Normal model with Hermite Polynomial Adjustment")
```

```{r}
# Set up the layout for the plots
par(mfrow = c(1, 2))

# Plot for Half-Normal model with Polynomial adjustment
plot(hn.poly.trunc0, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Half-Normal model with Polynomial Adjustment")

# Plot for Hazard Rate model with Cosine adjustment
plot(hr.cos.trunc0, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Hazard Rate model with Cosine Adjustment")
```

```{r}
# Set up the layout for the plots
par(mfrow = c(1, 2))

# Plot for Hazard Rate model with Hermite Polynomial adjustment
plot(hr.herm.trunc0, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Hazard Rate model with cosine Adjustment")

# Plot for Hazard Rate model with Polynomial adjustment
plot(hr.poly.trunc0, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Hazard Rate model with Polynomial Adjustment")
```

**Image Download**

```{r}
# Save the plots as PNG files
png("png/plots-hnherm-hncos.png", width = 800, height = 400) # Adjust width and height as needed
par(mfrow = c(1, 2))
plot(hn.herm.trunc0, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Half-normal with Hermite Polynomial ajustment")
plot(hn.cos.trunc0, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Half-normal with Cosine adjustment")
dev.off()

# Save the plots as PNG files
png("png/plots-hnploy-hrcos.png", width = 800, height = 400) # Adjust width and height as needed
par(mfrow = c(1, 2))
plot(hn.poly.trunc0, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Half-normal with polynomial adjustment")
plot(hr.cos.trunc0, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Hazard rate with cosine adjustment")
dev.off()

# Save the plots as PNG files
png("png/plots-hrpoly-hrherm", width = 800, height = 400) # Adjust width and height as needed
par(mfrow = c(1, 2))
plot(hr.poly.trunc0, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Hazard rate with polynomial adjustment")
plot(hr.herm.trunc0, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Hazard rate with hermite polynomial adjustment")
dev.off()
```

### III) Covariate Models

```{r}
print('model with Hazard rate Key function, with cov size')
hr.noadj.trunc0.cov.size <- ds(data = bowhead_LT, key = "hr", adjustment = NULL,convert_units = conversion, formula = ~size)

print('model with Hazard rate Key function, with cov size + bf')
hr.noadj.trunc0.cov.size.bf <- ds(data = bowhead_LT, key = "hr", adjustment = NULL,convert_units = conversion, formula = ~size + as.factor(bf))

print('model with Hazard rate Key function,  with cov size + bf + region')
hr.noadj.trunc0.cov.size.bf.region <- ds(data = bowhead_LT, key = "hr", adjustment = NULL,convert_units = conversion, formula = ~size + as.factor(Region.Label) + as.factor(bf))
```

```{r}
print('model with Half-normal Key function, with cov size')
hn.noadj.trunc0.cov.size <- ds(data = bowhead_LT, key = "hn", adjustment = NULL,convert_units = conversion, formula = ~size)

print('model with Half-normal Key function, with cov size + bf')
hn.noadj.trunc0.cov.size.bf <- ds(data = bowhead_LT, key = "hn", adjustment = NULL,convert_units = conversion, formula = ~size + as.factor(bf))

print('model with Half-normal Key function, with cov size + bf + region')
hn.noadj.trunc0.cov.size.bf.region <- ds(data = bowhead_LT, key = "hn", adjustment = NULL,convert_units = conversion, formula = ~size + as.factor(Region.Label) + as.factor(bf))
```

```{r}
# Set up the layout for the plots
par(mfrow = c(1, 2))

# Plot for Hazard Rate model with Hermite Polynomial adjustment
plot(hr.noadj.trunc0.cov.size, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Hazard Rate cov size")

# Plot for Hazard Rate model with Polynomial adjustment
plot(hr.noadj.trunc0.cov.size.bf, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Hazard Rate cov size + bf ")
```

```{r}
# Set up the layout for the plots
par(mfrow = c(1, 2))

# Plot for Hazard Rate model with Hermite Polynomial adjustment
plot(hr.noadj.trunc0.cov.size.bf.region, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Hazard Rate with cov size + bf + region")

# Plot for Hazard Rate model with Polynomial adjustment
plot(hn.noadj.trunc0.cov.size, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Half-normal cov size")
```

```{r}
# Set up the layout for the plots
par(mfrow = c(1, 2))

# Plot for Hazard Rate model with Hermite Polynomial adjustment
plot(hn.noadj.trunc0.cov.size.bf, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Half-normal cov size + bf")

# Plot for Hazard Rate model with Polynomial adjustment
plot(hn.noadj.trunc0.cov.size.bf.region, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Half-normal cov size + bf + region")
```

**Download**

```{r}
# Save the plots as PNG files
png("png/plots-hr0adjcovsize-hr0adfcovsizebf.png", width = 800, height = 400) # Adjust width and height as needed
par(mfrow = c(1, 2))
plot(hr.noadj.trunc0.cov.size, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Hazard Rate cov size")
plot(hr.noadj.trunc0.cov.size.bf, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Hazard Rate cov size + bf")
dev.off()

# Save the plots as PNG files
png("png/plots-hr0adjcovsizebfregion-hn0adjcovsize.png", width = 800, height = 400) # Adjust width and height as needed
par(mfrow = c(1, 2))
plot(hr.noadj.trunc0.cov.size.bf.region, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Hazard Rate cov size + bf + region")
plot(hn.noadj.trunc0.cov.size, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Half-normal cov size")
dev.off()

# Save the plots as PNG files
png("png/plots-hn0adjcovsizebf-hn0adjcovsizebfregion", width = 800, height = 400) # Adjust width and height as needed
par(mfrow = c(1, 2))
plot(hn.noadj.trunc0.cov.size.bf, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Half-normal cov size + bf")
plot(hn.noadj.trunc0.cov.size.bf.region, which = 2, pl.col = adjustcolor("lightblue", 0.5), border = NULL, lwd = 2, 
     ylab = "Detection probability (g(x))", xlab = "Distance", las = 1, 
     main = "Half-normal cov size + bf + region")
dev.off()
```

### V) Goodness of fit

```{r}
table <- summarize_ds_models(
  unif.noadj.trunc0,
  unif.cos.trunc0,
  hr.noadj.trunc0,
  hn.noadj.trunc0,
  hn.cos.trunc0,
  hn.herm.trunc0,
  hn.poly.trunc0,
  hr.cos.trunc0,
  hr.herm.trunc0,
  hr.poly.trunc0,
  hr.noadj.trunc0.cov.size,
  hr.noadj.trunc0.cov.size.bf,
  hr.noadj.trunc0.cov.size.bf.region,
  hn.noadj.trunc0.cov.size,
  hn.noadj.trunc0.cov.size.bf,
  hn.noadj.trunc0.cov.size.bf.region, output = 'plain')
```

```{r}
gof_ds(unif.noadj.trunc0)
gof_ds(unif.noadj.trunc0, ks= TRUE)
```

```{r}
gof_ds(unif.cos.trunc0)
gof_ds(unif.cos.trunc0, ks= TRUE)
```

```{r}
gof_ds(hr.noadj.trunc0)
gof_ds(hr.noadj.trunc0, ks= TRUE)
```

```{r}
gof_ds(hn.noadj.trunc0)
gof_ds(hn.noadj.trunc0, ks= TRUE)
```

```{r}
gof_ds(hn.cos.trunc0)
gof_ds(hn.cos.trunc0, ks= TRUE)
```

```{r}
gof_ds(hn.herm.trunc0)
gof_ds(hn.herm.trunc0, ks= TRUE)
```

```{r}
gof_ds(hn.poly.trunc0)
gof_ds(hn.poly.trunc0, ks= TRUE)
```

```{r}
gof_ds(hr.cos.trunc0)
gof_ds(hr.cos.trunc0, ks= TRUE)
```

```{r}
gof_ds(hr.herm.trunc0)
gof_ds(hr.herm.trunc0, ks= TRUE)
```

```{r}
gof_ds(hr.poly.trunc0)
gof_ds(hr.poly.trunc0, ks= TRUE)
```

```{r}
gof_ds(hr.noadj.trunc0.cov.size)
gof_ds(hr.noadj.trunc0.cov.size, ks= TRUE)
```

```{r}
gof_ds(hr.noadj.trunc0.cov.size.bf)
gof_ds(hr.noadj.trunc0.cov.size.bf, ks= TRUE)
```

```{r}
gof_ds(hr.noadj.trunc0.cov.size.bf.region)
gof_ds(hr.noadj.trunc0.cov.size.bf.region, ks= TRUE)
```

```{r}
gof_ds(hn.noadj.trunc0.cov.size)
gof_ds(hn.noadj.trunc0.cov.size, ks= TRUE)
```

```{r}
gof_ds(hn.noadj.trunc0.cov.size.bf)
gof_ds(hn.noadj.trunc0.cov.size.bf, ks= TRUE)
```

```{r}
gof_ds(hn.noadj.trunc0.cov.size.bf.region)
gof_ds(hn.noadj.trunc0.cov.size.bf.region, ks= TRUE)
```

# Estimate Abundance

Now when we get the numbers we should choose a couple models and run this function with it in order to see what are estimates are. This is turn will enable us to to comment on them with the Analysis of the results in the next section

```{r}
# Estimate function for model unif.noadj.trunc0
estimate_unif.noadj.trunc0 <- function(region_table, sample_table, observation_table) {
  dht(model = unif.noadj.trunc0$ddf, 
      region.table = region_table,
      sample.table = sample_table,
      obs.table = observation_table)
}

# Estimate function for model unif.cos.trunc0
estimate_unif.cos.trunc0 <- function(region_table, sample_table, observation_table) {
  dht(model = unif.cos.trunc0$ddf, 
      region.table = region_table,
      sample.table = sample_table,
      obs.table = observation_table)
}

# Estimate function for model hr.noadj.trunc0
estimate_hr.noadj.trunc0 <- function(region_table, sample_table, observation_table) {
  dht(model = hr.noadj.trunc0$ddf, 
      region.table = region_table,
      sample.table = sample_table,
      obs.table = observation_table)
}

# Estimate function for model hn.noadj.trunc0
estimate_hn.noadj.trunc0 <- function(region_table, sample_table, observation_table) {
  dht(model = hn.noadj.trunc0$ddf, 
      region.table = region_table,
      sample.table = sample_table,
      obs.table = observation_table)
}

# Estimate function for model hn.cos.trunc0
estimate_hn.cos.trunc0 <- function(region_table, sample_table, observation_table) {
  dht(model = hn.cos.trunc0$ddf, 
      region.table = region_table,
      sample.table = sample_table,
      obs.table = observation_table)
}

# Estimate function for model hn.herm.trunc0
estimate_hn.herm.trunc0 <- function(region_table, sample_table, observation_table) {
  dht(model = hn.herm.trunc0$ddf, 
      region.table = region_table,
      sample.table = sample_table,
      obs.table = observation_table)
}

# Estimate function for model hn.poly.trunc0
estimate_hn.poly.trunc0 <- function(region_table, sample_table, observation_table) {
  dht(model = hn.poly.trunc0$ddf, 
      region.table = region_table,
      sample.table = sample_table,
      obs.table = observation_table)
}

# Estimate function for model hr.cos.trunc0
estimate_hr.cos.trunc0 <- function(region_table, sample_table, observation_table) {
  dht(model = hr.cos.trunc0$ddf, 
      region.table = region_table,
      sample.table = sample_table,
      obs.table = observation_table)
}

# Estimate function for model hr.herm.trunc0
estimate_hr.herm.trunc0 <- function(region_table, sample_table, observation_table) {
  dht(model = hr.herm.trunc0$ddf, 
      region.table = region_table,
      sample.table = sample_table,
      obs.table = observation_table)
}

# Estimate function for model hr.poly.trunc0
estimate_hr.poly.trunc0 <- function(region_table, sample_table, observation_table) {
  dht(model = hr.poly.trunc0$ddf, 
      region.table = region_table,
      sample.table = sample_table,
      obs.table = observation_table)
}

# Estimate function for model hr.noadj.trunc0.cov.size
estimate_hr.noadj.trunc0.cov.size <- function(region_table, sample_table, observation_table) {
  dht(model = hr.noadj.trunc0.cov.size$ddf, 
      region.table = region_table,
      sample.table = sample_table,
      obs.table = observation_table)
}

# Estimate function for model hr.noadj.trunc0.cov.size.bf
estimate_hr.noadj.trunc0.cov.size.bf <- function(region_table, sample_table, observation_table) {
  dht(model = hr.noadj.trunc0.cov.size.bf$ddf, 
      region.table = region_table,
      sample.table = sample_table,
      obs.table = observation_table)
}

# Estimate function for model hr.noadj.trunc0.cov.size.bf.region
estimate_hr.noadj.trunc0.cov.size.bf.region <- function(region_table, sample_table, observation_table) {
  dht(model = hr.noadj.trunc0.cov.size.bf.region$ddf, 
      region.table = region_table,
      sample.table = sample_table,
      obs.table = observation_table)
}

# Estimate function for model hn.noadj.trunc0.cov.size
estimate_hn.noadj.trunc0.cov.size <- function(region_table, sample_table, observation_table) {
  dht(model = hn.noadj.trunc0.cov.size$ddf, 
      region.table = region_table,
      sample.table = sample_table,
      obs.table = observation_table)
}

# Estimate function for model hn.noadj.trunc0.cov.size.bf
estimate_hn.noadj.trunc0.cov.size.bf <- function(region_table, sample_table, observation_table) {
  dht(model = hn.noadj.trunc0.cov.size.bf$ddf, 
      region.table = region_table,
      sample.table = sample_table,
      obs.table = observation_table)
}

# Estimate function for model hn.noadj.trunc0.cov.size.bf.region
estimate_hn.noadj.trunc0.cov.size.bf.region <- function(region_table, sample_table, observation_table) {
  dht(model = hn.noadj.trunc0.cov.size.bf.region$ddf, 
      region.table = region_table,
      sample.table = sample_table,
      obs.table = observation_table)
}


```

# Analysis of the results

This is the sort of analysis we need

*As we expect detectability to be affected by the covariates, the next step is to include these in the modelling of the detection function. We therefore consider both the hazard-rate and the half-normal model with various combinations of covariates. (We do not consider models that include both the continuous covariate mas and the factor hour as the two variables are highly correlated.) Results appear in Table 5.7. None of the models with the hazard-rate key require adjustment terms, while the half-normal models always require cosine terms. The covariate representing observer seems to be very important in explaining detectability; all models that include it have a considerably lower AIC than any of the CDS models or any of the other MCDS models without this covariate. Overall, detectability, as reflected by the estimates of the effective detection radius, is relatively constant across models, suggesting that the analysis is robust to model choice*

-   Remember that we are underestimating the whales because some of them will be under water
